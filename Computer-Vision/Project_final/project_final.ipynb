{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacc261a-f9a9-4c2a-bcd0-cf7b8b6c6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32454a17-755b-4b1c-8d4a-ea325aefc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sfm(dataset_number):\n",
    "    K, img_names, init_pair, pixel_threshold = get_dataset_info(dataset_number)\n",
    "    images = [cv2.cvtColor(cv2.imread(img_name), cv2.COLOR_BGR2GRAY) for img_name in img_names]\n",
    "    num_images = len(img_names)\n",
    "    focal_length = K[0][0]\n",
    "    epipolar_threshold = pixel_threshold / focal_length\n",
    "    homography_threshold = 3 * pixel_threshold / focal_length\n",
    "    translation_threshold = 3 * pixel_threshold / focal_length\n",
    "    sift = cv2.SIFT_create()\n",
    "    P1 = np.eye(3,4)\n",
    "    Rs = []\n",
    "    Rs.append(P1[:3,:3])\n",
    "    step6_inliers = []\n",
    "    \n",
    "    \n",
    "    for i in range(num_images - 1):\n",
    "        x1, x2 = image_points(images[i], images[i + 1])\n",
    "        x1_hom  = np.vstack((x1, np.ones(x1.shape[1])))\n",
    "        x2_hom  = np.vstack((x2, np.ones(x2.shape[1])))\n",
    "        x1n = normalize_points(x1_hom, K)\n",
    "        x2n = normalize_points(x2_hom, K)\n",
    "        E_best, inliers = estimate_E_robust(x1n, x2n,K, epipolar_threshold)\n",
    "        step6_inliers.append(inliers)\n",
    "        x1_inliers = x1n[:, inliers]\n",
    "        x2_inliers = x2n[:, inliers]\n",
    "        \n",
    "        P2,_ = best_P(E_best,K,P1,x1_inliers,x2_inliers)\n",
    "        R = P2[:, :3]\n",
    "        \n",
    "        upgrade_R = R @ Rs[i]\n",
    "        Rs.append(upgrade_R)\n",
    "\n",
    "\n",
    "    i1, i2 = init_pair[0] - 1, init_pair[1] - 1\n",
    "    X0_world, desc_X = reconstruct_initial_3D(i1,i2,images,epipolar_threshold, K, P1, Rs)\n",
    "\n",
    "    Ts = []\n",
    "    for i in range(num_images):\n",
    "        kp, desc = sift.detectAndCompute(images[i], None)\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(desc, desc_X, k=2)\n",
    "    \n",
    "        filtered_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.80 * n.distance:\n",
    "                filtered_matches.append(m)\n",
    "        \n",
    "        xs = np.array([kp[m.queryIdx].pt for m in filtered_matches]).T\n",
    "        Xs = X0_world[:, [m.trainIdx for m in filtered_matches]]\n",
    "\n",
    "        xs_hom = np.vstack((xs, np.ones(xs.shape[1])))\n",
    "        xsn = normalize_points(xs_hom,K)\n",
    "        \n",
    "        P, inliers_idx = estimate_T_robust(xsn, Xs, Rs[i], translation_threshold)\n",
    "        Ts.append(P[:, -1])\n",
    "\n",
    "\n",
    "    final_X = []\n",
    "    Ps = []\n",
    "    for i in range(len(images)): \n",
    "        Ps.append(np.hstack((Rs[i], Ts[i].reshape(-1, 1))))\n",
    "    \n",
    "    for i in range(len(images) - 1):\n",
    "        kp1, des1 = sift.detectAndCompute(images[i], None)\n",
    "        kp2, des2 = sift.detectAndCompute(images[i+1], None)\n",
    "        \n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "        filtered_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.80 * n.distance:\n",
    "                filtered_matches.append(m)\n",
    "        \n",
    "        x1 = np.array([kp1[m.queryIdx].pt for m in filtered_matches]).T\n",
    "        x2 = np.array([kp2[m.trainIdx].pt for m in filtered_matches]).T\n",
    "        \n",
    "        x1_hom = np.vstack((x1, np.ones(x1.shape[1])))\n",
    "        x2_hom = np.vstack((x2, np.ones(x2.shape[1])))\n",
    "    \n",
    "        x1n = normalize_points(x1_hom, K)\n",
    "        x2n = normalize_points(x2_hom, K)\n",
    "     \n",
    "        P1 = Ps[i]\n",
    "        P2 = Ps[i+1]\n",
    "    \n",
    "        X = triangulate_all_points(P1, P2, x1n[:,step6_inliers[i]], x2n[:,step6_inliers[i]])\n",
    "    \n",
    "        X_mean = np.mean(X, axis=1)\n",
    "        X_dist = np.linalg.norm(X - X_mean[:, np.newaxis], axis=0)\n",
    "        \n",
    "        threshold = 2 * np.percentile(X_dist, 90)\n",
    "        X_inliners = X[:, X_dist <= threshold]\n",
    "        \n",
    "    \n",
    "        final_X.append(X_inliners)\n",
    "\n",
    "    \n",
    "    plot_3d_points_and_cameras_with_principal_axes(final_X,Ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae89837-7c6a-489e-93c6-ce42d7d55e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change input number in \"run_sfm()\" to the dataset you want to run\n",
    "run_sfm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dbae9-3bd1-4a24-8242-780a270c1cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
